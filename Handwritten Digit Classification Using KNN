import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits


digit_data = load_digits()
image_pixels = digit_data.data
digit_labels = digit_data.target

plt.figure(figsize=(10, 4))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(image_pixels[i].reshape(8, 8), cmap='gray')
    plt.title(f'Digit: {digit_labels[i]}')
plt.show()


shuffled_indices = np.random.permutation(len(image_pixels))
training_split = int(0.8 * len(image_pixels))
train_images, test_images = image_pixels[shuffled_indices[:training_split]], image_pixels[shuffled_indices[training_split:]]
train_labels, test_labels = digit_labels[shuffled_indices[:training_split]], digit_labels[shuffled_indices[training_split:]]

def calculate_euclidean_distance(vector1, vector2):
    return np.sqrt(np.sum((vector1 - vector2) ** 2))

def perform_k_nearest_neighbors(training_images, training_labels, testing_images, neighbors_count=3):
    predictions = []
    for test_image in testing_images:
        distances = np.array([calculate_euclidean_distance(test_image, train_image) for train_image in training_images])
        nearest_neighbors_indices = np.argsort(distances)[:neighbors_count]
        nearest_neighbors_labels = training_labels[nearest_neighbors_indices]
        most_common_label = np.bincount(nearest_neighbors_labels).argmax()
        predictions.append(most_common_label)
    return np.array(predictions)

def compute_accuracy_score(true_labels, predicted_labels, normalize=True, weight=None):
    correct_predictions = (true_labels == predicted_labels)
    if weight is not None:
        correct_predictions = correct_predictions * weight
    score = correct_predictions.sum()
    if normalize:
        return score / len(true_labels)
    return score

def generate_confusion_matrix(true_labels, predicted_labels, class_labels=None):
    if class_labels is None:
        class_labels = np.unique(true_labels)
    confusion_matrix = np.zeros((len(class_labels), len(class_labels)), dtype=int)
    for true, pred in zip(true_labels, predicted_labels):
        true_index = np.where(class_labels == true)[0][0]
        pred_index = np.where(class_labels == pred)[0][0]
        confusion_matrix[true_index, pred_index] += 1
    return confusion_matrix


neighbor_values = [1, 3, 5, 100, 500]
evaluation_results = {}
for k in neighbor_values:
    predicted_labels = perform_k_nearest_neighbors(train_images, train_labels, test_images, k)
    accuracy = compute_accuracy_score(test_labels, predicted_labels)
    cm = generate_confusion_matrix(test_labels, predicted_labels)
    evaluation_results[k] = {'accuracy': accuracy, 'confusion_matrix': cm}
    print(f'k={k}, Accuracy={accuracy:.4f}')


for k in neighbor_values:
    print(f'Confusion Matrix for k={k}:')
    print(evaluation_results[k]['confusion_matrix'])
